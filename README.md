# AI4Code
[Ссылка на соревнование](https://www.kaggle.com/competitions/AI4Code/overview)

[Наш краткий обзор чужих решении для вдоохновления](https://docs.google.com/spreadsheets/d/1SUhyGX7rEqw5tliUc_5ylG9BDm7MyAWUCInqgOdTdA0/edit?usp=sharing)

[Ссылка на презентацию](https://docs.google.com/presentation/d/1I6YtowvGsIflBMlEvuyLKOpo4OrF4i3Y4k-PAwYWgU0/edit#slide=id.g34369dacab2_0_33)

Найдейно интересное соревнование, которое предложит нам вызов как мльщикам. 
План действий прост: сначала исследование чужих решений, затем их реализации, обработка под себя | поиск свежих решении от себя
(это на уровней идей, по сути хотим создать франкенштейна), разбор супер пк, реализация собественного решения.

Шаги(ниже описаное то как мы примерное видели задачу):
- краткое ознакомление с задачей и датасетом. UPD:DONE
- осмотр чужих решении из топа и их обзор, выжимка важный идей и замечаний из этого. UPD:DONE
- выбор нескольких токенайзеров (простое и сложное, то есть хотим хотя бы разок попробовать на основе BOW(с n-граммами), а потом всякие берты). UPD:DONE
- определение архитектур моделей и типа задачи. UPD:DONE
- ознаколение с СуперПК для вычисления и получение к нему доступа. UPD:DONE
- запуск на СуперПК обучения какой-нибудь тяжелой и веселой модели. UPD:DONE
- улучшение полученных идей. UPD:DONE

На данный момент мы нашли несколько реализаций на основе берта (токенайзер), и роберта (как сама модель),
простейшая нейронка для ранжирования, код для создания BOW(n-граммы), TF-IDF (совсем черновой). 
Также разобрались с такой крупной задачей как использование СуперПК, сделали универсальный скрипт для запуска кода через очередь 
по времени и создание необходиомго окружения, учим диффузионку для тестового прогона. Сейчас на этапе формирования своего обучения токенезаторов.

Из актуальных проблем:
- неясно как добавить в супер пк новые модели универсальным образом (тк там на кластерах нет доступа в интернет).
- автоматическое сохранение результатов на СуперПК (тк там на кластерах нет доступа в интернет). UPD: Сделали логирвание, но из-за ограчния по памяти иногда надо было что-то удалять, чтобы сохранять новое
- вопрос использования одного пространства на СуперПК (смиримся, что нет гита, но хотя бы из одного и того же места подкачивать свои же модели)
- как распараллелить вычисления батчей и обучение моделей в торче. UPD: С помощью DataParallel и подбора размера батчей смогли ускорить код порядка 4 раз на обучении. Также в 2-4 раза для токенизации.
- продолжить разборы чужих модей для выжимок 
- придумать еще метрики кроме пермутации (Kendall Tau correlation) для сравнения результатов. UPD: NDCG для XGBoost, accuracy на парах из двух, чтобы иметь нижнюю оценку

  


## UPD отчета:
- смогли реализовать модели pairwise (CodeBert), listwise(CodeBert), pairwise(CodeBert + Mult), XGBoost(FastText)
- эскперименты с моделями ставлись на разных объёмаъ данных для трейна_теста (20k_2k, 30k_5k, 50k_5k, 100k_27k)
- Есть несколько неудавшихся решении в blacklist.ipynb(это ллама и мешок слов с накрученым вниманием)
- Лучший результат это pairwise(CodeBert + Mult) на 30k_5k tau-score = 0.67, на всех данных tau-score = 0.48
- Для того чтобы понять насколько хорошо решение было решение сравнили его с рандомным ранжирование у которого tau-score на любом размере выборки меньше 0.004
  
 train_test\model   |  XGBoost(FastText)  |  Listwise(CodeBert + mult)  |  Pairwise(CodeBert)  |  Pairwise(CodeBert + mult)  |  Случайное ранжирование \n
      20k_2k        |        0.31         |               -             |           -          |            0.61             |     -0.0005 ± 0.0004\n
      30k_5k        |        0.28         |               -             |         0.28         |            0.67             |     -0.0004 ± 0.0008\n
      50k_5k        |        0.23         |              0.28           |         0.3          |              -              |     -0.0004 ± 0.0007\n
      100k_27k      |        0.11         |              0.15           |           -          |            0.48             |      0.0038 ± 0.0002\n


  
## Структура PairWise решения:
- Datasets - работа с данными:
    - cell.py - класс, для хранения токенизированной ячейки
    - cell_dataset.py - базовый класс датасета
    - train_val_cell_dataset.py - класс тренировочного и валидационного датасетов
    - sampler.py - сэмплер для тренировочного и валидационного даталоадеров
    - test_cell_dataset.py - класс тестового датасета
- utils.py - вычисление метрики Kendall Tau correlation и другие вспомогательные функции
- model.py - модель для определения порядка ячеек
- train.py - обучение модели, вычисление функции потерь и обновление параметров
- test.py - вычисление качества работы модели по метрике Kendall Tau correlation
- main.py - основной исполняемый файл
