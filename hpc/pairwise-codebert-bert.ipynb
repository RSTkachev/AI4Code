{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from transformers import BertModel, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from time import time, localtime, strftime\n",
    "from bisect import bisect\n",
    "from functools import cmp_to_key\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "# /home/drkocharyan/ai4code/AI4Code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_path\": \"/home/drkocharyan/ai4code/AI4Code/train/\",\n",
    "    \"train_orders_path\": \"/home/drkocharyan/ai4code/AI4Code/train_orders.csv\",\n",
    "    \n",
    "    \"code_model_name\": \"microsoft/codebert-base\",\n",
    "    \"text_model_name\": \"bert-base-multilingual-uncased\",\n",
    "    \n",
    "    \"train_size\": 0.7,\n",
    "    \"valid_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \n",
    "    \"train_samples\": 90000,\n",
    "    \"valid_samples\": 5000,\n",
    "    \"test_samples\": 2000,\n",
    "    \n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout_prob\": 0.1,\n",
    "    \"max_length\": 128,\n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"early_stopping\": 5,\n",
    "    \"saving_freq\": 5,\n",
    "    \"learning_rate\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def prepare_folders():\n",
    "    current_time = strftime(\"%d.%m.%Y-%H.%M\", localtime())\n",
    "    savedir = f\"./checkpoints/{current_time}/\"\n",
    "\n",
    "    if not os.path.exists(\"./checkpoints\"):\n",
    "        os.mkdir(\"./checkpoints/\")\n",
    "    if not os.path.exists(savedir):\n",
    "        os.mkdir(savedir)\n",
    "    else:\n",
    "        for root, dirs, files in os.walk(savedir, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "\n",
    "    return savedir\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "    return device\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "\n",
    "class Cell:\n",
    "    def __init__(self, input_ids, att_mask, cell_type):\n",
    "        self.input_ids = input_ids\n",
    "        self.att_mask = att_mask\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def get(self):\n",
    "        return (self.input_ids, self.att_mask, self.cell_type)\n",
    "\n",
    "\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.code_tokenizer = code_tokenizer\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.files = {}\n",
    "\n",
    "        for filename in tqdm(self.data.index, desc=\"Processing dataset\"):\n",
    "            cells_dict = {}\n",
    "            cells = self.data.loc[filename, \"cell_order\"]\n",
    "            with open(f\"{path}{filename}.json\") as file:\n",
    "                json_code = json.load(file)\n",
    "            for cell in cells:\n",
    "                input_ids, att_mask, cell_type = self.prepare_data(\n",
    "                    json_code[\"cell_type\"][cell], json_code[\"source\"][cell]\n",
    "                )\n",
    "                cells_dict[cell] = Cell(input_ids, att_mask, cell_type)\n",
    "            self.files[filename] = cells_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self, cell_type, cell_content):\n",
    "        if cell_type == \"code\":\n",
    "            tokenizer = self.code_tokenizer\n",
    "            type_label = 1\n",
    "        else:\n",
    "            tokenizer = self.text_tokenizer\n",
    "            type_label = 0\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            cell_content,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "    \n",
    "        type_tensor = torch.tensor([type_label], dtype=torch.long)\n",
    "\n",
    "        return (tokens[\"input_ids\"], tokens[\"attention_mask\"], type_tensor)\n",
    "\n",
    "\n",
    "class TrainValCellDataset(CellDataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length):\n",
    "        super().__init__(path, data, code_tokenizer, text_tokenizer, max_length)\n",
    "\n",
    "        n_pair = 0\n",
    "        for row_index in self.data.index:\n",
    "            n_pair += len(self.data.loc[row_index, \"cell_order\"]) - 1\n",
    "        self.n_pair = n_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_pair\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = idx[0]\n",
    "        first_cell_id = idx[1]\n",
    "        second_cell_id = idx[2]\n",
    "\n",
    "        first_position = self.data.loc[filename, \"cell_order\"].index(first_cell_id)\n",
    "        second_position = self.data.loc[filename, \"cell_order\"].index(second_cell_id)\n",
    "        order = 0 if first_position < second_position else 1\n",
    "\n",
    "        return ((self.files[filename][first_cell_id].get(), self.files[filename][second_cell_id].get()), order)\n",
    "\n",
    "\n",
    "class TestCellDataset(CellDataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length):\n",
    "        super().__init__(path, data, code_tokenizer, text_tokenizer, max_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.data.iloc[idx].name\n",
    "        correct_order = self.data.iloc[idx].item()\n",
    "        random_order = correct_order.copy()\n",
    "        np.random.shuffle(random_order)\n",
    "\n",
    "        cells = []\n",
    "        for index in random_order:\n",
    "            input_ids, att_mask, cell_type = self.files[file_id][index].get()\n",
    "            cells.append([index, input_ids, att_mask, cell_type])\n",
    "\n",
    "        return cells, correct_order\n",
    "\n",
    "\n",
    "class CellSampler(Sampler):\n",
    "    def __init__(self, data, seed=None):\n",
    "        self.data = data\n",
    "        self.seed = seed\n",
    "        n_pair = 0\n",
    "        for row_index in self.data.index:\n",
    "            n_pair += len(self.data.loc[row_index, \"cell_order\"]) - 1\n",
    "        self.n_pair = n_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_pair\n",
    "\n",
    "    def __iter__(self):\n",
    "        pairs = []\n",
    "        for row_index in self.data.index:\n",
    "            cells = self.data.loc[row_index, \"cell_order\"].copy()\n",
    "            if self.seed:\n",
    "                rng = np.random.default_rng(self.seed)\n",
    "                rng.shuffle(cells)\n",
    "            else:\n",
    "                np.random.shuffle(cells)\n",
    "            for cell_index in range(len(cells) - 1):\n",
    "                pairs.append([row_index, cells[cell_index], cells[cell_index + 1]])\n",
    "\n",
    "        for pair in pairs:\n",
    "            yield pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "class OrderPredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_prob=0.1):\n",
    "        super(OrderPredictionModel, self).__init__()\n",
    "\n",
    "        self.bert_text = BertModel.from_pretrained(config[\"text_model_name\"])\n",
    "        self.codebert = AutoModel.from_pretrained(config[\"code_model_name\"])\n",
    "\n",
    "        self.type_embedding = nn.Embedding(2, 8)\n",
    "        self.fc1 = nn.Linear(768 * 2 + 8 * 2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_batch_embeddings(input_ids, attention_mask, cell_type, code_model, text_model):\n",
    "        device = input_ids.device\n",
    "        batch_size = input_ids.size(0)\n",
    "        hidden_size = code_model.config.hidden_size\n",
    "        embeddings = torch.zeros(batch_size, hidden_size, device=device, dtype=torch.float32)\n",
    "\n",
    "        code_mask = (cell_type == 1)\n",
    "        text_mask = (cell_type == 0)\n",
    "\n",
    "        if code_mask.any():\n",
    "            code_indices = code_mask.nonzero(as_tuple=True)[0]\n",
    "            code_input_ids = input_ids[code_indices]\n",
    "            code_attention_mask = attention_mask[code_indices]\n",
    "            out_code = code_model(code_input_ids, attention_mask=code_attention_mask).pooler_output\n",
    "            embeddings[code_indices] = out_code\n",
    "\n",
    "        if text_mask.any():\n",
    "            text_indices = text_mask.nonzero(as_tuple=True)[0]\n",
    "            text_input_ids = input_ids[text_indices]\n",
    "            text_attention_mask = attention_mask[text_indices]\n",
    "            out_text = text_model(text_input_ids, attention_mask=text_attention_mask).pooler_output\n",
    "            embeddings[text_indices] = out_text\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def forward(self, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2):\n",
    "        embedding1 = self._get_batch_embeddings(input_ids1, att_mask1, cell_type1, \n",
    "                                                code_model=self.codebert, text_model=self.bert_text)\n",
    "\n",
    "        embedding2 = self._get_batch_embeddings(input_ids2, att_mask2, cell_type2, \n",
    "                                               code_model=self.codebert, text_model=self.bert_text)\n",
    "\n",
    "        type_emb1 = self.type_embedding(cell_type1)\n",
    "        type_emb2 = self.type_embedding(cell_type2)\n",
    "\n",
    "        combined = torch.cat([embedding1, type_emb1, embedding2, type_emb2], dim=1)\n",
    "        x = torch.relu(self.bn1(self.fc1(combined)))\n",
    "        x = self.dropout(x)\n",
    "        output = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return output.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        valid_dataloader,\n",
    "        savedir,\n",
    "        device,\n",
    "        epochs=10,\n",
    "        early_stopping=5,\n",
    "        saving_freq=5,\n",
    "        lr=1e-4,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optimizer = optim.NAdam(self.model.parameters(), lr=lr)\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        self.best_score = -float(\"inf\")\n",
    "        self.best_model = None\n",
    "        self.savedir = savedir\n",
    "        self.saving_freq = saving_freq\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.valid_kendalls = []\n",
    "\n",
    "    def train(self):\n",
    "        early_stopping_remaining = self.early_stopping\n",
    "        print(\"*\" * 80)\n",
    "        print(f\"Train model\")\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            print(\"*\" * 80)\n",
    "            print(f\"Epoch {epoch}/{self.epochs}\")\n",
    "            start_time = time()\n",
    "            train_loss = self._train_one_epoch()\n",
    "            valid_score = self._validate()\n",
    "\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.valid_kendalls.append(valid_score)\n",
    "            \n",
    "            print(f\"Train loss: {train_loss:.4f}, Valid accuracy: {valid_score:.4f}\")\n",
    "            print(f\"Epoch execution time: {time() - start_time:.2f} seconds\")\n",
    "\n",
    "            if valid_score > self.best_score:\n",
    "                early_stopping_remaining = self.early_stopping\n",
    "                self.best_score = valid_score\n",
    "                self.best_model = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "                print(f\"New best model saved with valid accuracy: {valid_score:.4f}\")\n",
    "            else:\n",
    "                early_stopping_remaining -= 1\n",
    "\n",
    "            if epoch % self.saving_freq == 0:\n",
    "                self._save_checkpoint(epoch, train_loss)\n",
    "\n",
    "            if not early_stopping_remaining:\n",
    "                print(f\"Training stopped at {epoch} epoch\")\n",
    "                break\n",
    "\n",
    "        if self.best_model:\n",
    "            torch.save(self.best_model, f\"{self.savedir}best_model.pt\")\n",
    "            print(\"Best model saved as 'best_model.pt'.\")\n",
    "        \n",
    "        return self.train_losses, self.valid_kendalls\n",
    "\n",
    "    def _train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        for (first_cell, second_cell), train_label in tqdm(self.train_dataloader, desc=\"Training\"):\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(\n",
    "                first_cell[0].squeeze(1).to(self.device),\n",
    "                first_cell[1].squeeze(1).to(self.device),\n",
    "                first_cell[2].squeeze(1).to(self.device),\n",
    "                second_cell[0].squeeze(1).to(self.device),\n",
    "                second_cell[1].squeeze(1).to(self.device),\n",
    "                second_cell[2].squeeze(1).to(self.device),\n",
    "            )\n",
    "            loss = self.criterion(output, train_label.float().to(self.device))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        return train_loss / n_batches\n",
    "    \n",
    "\n",
    "    def _validate(self):\n",
    "        self.model.eval()\n",
    "        score = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (first_cell, second_cell), correct_order in tqdm(self.valid_dataloader, desc=\"Validating\"):\n",
    "                n_batches += 1\n",
    "                output = self.model(\n",
    "                    first_cell[0].squeeze(1).to(self.device),\n",
    "                    first_cell[1].squeeze(1).to(self.device),\n",
    "                    first_cell[2].squeeze(1).to(self.device),\n",
    "                    second_cell[0].squeeze(1).to(self.device),\n",
    "                    second_cell[1].squeeze(1).to(self.device),\n",
    "                    second_cell[2].squeeze(1).to(self.device),\n",
    "                )\n",
    "\n",
    "                output += 0.5\n",
    "                order = output.to(dtype=torch.int32).cpu()\n",
    "                score += sum(order == correct_order).sum() / correct_order.shape[0]\n",
    "\n",
    "        score /= n_batches\n",
    "        return score\n",
    "\n",
    "    def _save_checkpoint(self, epoch, train_loss):\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": {k: v.cpu() for k, v in self.model.state_dict().items()},\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"train_loss\": train_loss,\n",
    "        }\n",
    "        checkpoint_path = f\"{self.savedir}checkpoint_epoch_{epoch}.pt\"\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}.\")\n",
    "\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def test(self, test_dataloader):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        true_order = []\n",
    "        predicted_order = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for cells, correct_order in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "                sorted_cells = sorted(cells, key=cmp_to_key(self._custom_compare))\n",
    "                sorted_order = [cell[0] for cell in sorted_cells]\n",
    "                true_order.append(correct_order)\n",
    "                predicted_order.append(sorted_order)\n",
    "\n",
    "        return kendall_tau(true_order, predicted_order)\n",
    "\n",
    "    def _custom_compare(self, cell1, cell2):\n",
    "        result = self.model(\n",
    "            cell1[1].squeeze(0).to(self.device),\n",
    "            cell1[2].squeeze(0).to(self.device),\n",
    "            cell1[3].squeeze(0).to(self.device),\n",
    "            cell2[1].squeeze(0).to(self.device),\n",
    "            cell2[2].squeeze(0).to(self.device),\n",
    "            cell2[3].squeeze(0).to(self.device),\n",
    "        )\n",
    "\n",
    "        if result.item() <= 0.5:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка train_tokenized_full.pkl: 100%|██████████| 13.2G/13.2G [24:20<00:00, 9.06MB/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# Функция для сохранения токенизированных данных\n",
    "def save_tokenized_data(dataset, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "\n",
    "# Сохранение тренировочных и валидационных данных\n",
    "# save_tokenized_data(train_dataset, 'train_tokenized_10k.pkl')\n",
    "# save_tokenized_data(valid_dataset, 'valid_tokenized_2k.pkl')\n",
    "# save_tokenized_data(train_dataset, 'train_tokenized_10k.pkl')\n",
    "# save_tokenized_data(valid_dataset, 'valid_tokenized_2k.pkl')\n",
    "# save_tokenized_data(test_dataset, 'test_tokenized_1k.pkl')\n",
    "# def load_tokenized_data(filename):\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         return pickle.load(f)\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_tokenized_data(filename):\n",
    "    file_size = os.path.getsize(filename)\n",
    "    \n",
    "    with open(filename, 'rb') as f:\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=f\"Загрузка {filename}\") as pbar:\n",
    "            data = pickle.load(f)\n",
    "            # Обновляем прогресс-бар до 100% после загрузки\n",
    "            pbar.n = file_size\n",
    "            pbar.refresh()\n",
    "    \n",
    "    return data\n",
    "# Загрузка тренировочных и валидационных данных\n",
    "train_dataset_ = load_tokenized_data('train_tokenized_full.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка valid_tokenized_full.pkl: 100%|██████████| 3.79G/3.79G [08:35<00:00, 7.36MB/s]\n"
     ]
    }
   ],
   "source": [
    "valid_dataset_ = load_tokenized_data('valid_tokenized_full.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Загрузка test_tokenized_full.pkl: 100%|██████████| 1.89G/1.89G [04:37<00:00, 6.80MB/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset_ = load_tokenized_data('test_tokenized_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Reading data\n",
      "********************************************************************************\n",
      "Creating datasets and dataloaders\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "np.random.seed(42)\n",
    "print(\"*\" * 80)\n",
    "print(\"Reading data\")\n",
    "\n",
    "code_tokenizer = AutoTokenizer.from_pretrained(config[\"code_model_name\"])\n",
    "text_tokenizer = BertTokenizer.from_pretrained(config[\"text_model_name\"])\n",
    "\n",
    "info = pd.read_csv(config[\"train_orders_path\"], index_col=\"id\")\n",
    "info[\"cell_order\"] = info[\"cell_order\"].apply(lambda x: x.split())\n",
    "indeces = list(info.index)\n",
    "\n",
    "rng = np.random.default_rng(config[\"random_seed\"])\n",
    "rng.shuffle(indeces)\n",
    "\n",
    "train_border = int(config[\"train_size\"] * len(indeces))\n",
    "valid_border = int((config[\"train_size\"] + config[\"valid_size\"]) * len(indeces))\n",
    "\n",
    "train_data = info.loc[indeces[:train_border]]\n",
    "valid_data = info.loc[indeces[train_border:valid_border]]\n",
    "test_data = info.loc[indeces[valid_border:]]\n",
    "\n",
    "# подвыборки для теста\n",
    "# train_data_short = train_data.iloc[:config[\"train_samples\"]]\n",
    "# valid_data_short = valid_data.iloc[:config[\"valid_samples\"]]\n",
    "# test_data_short = test_data.iloc[:config[\"test_samples\"]]\n",
    "\n",
    "# print(f\"Train samples: {len(train_data_short)}\")\n",
    "# print(f\"Validation samples: {len(valid_data_short)}\")\n",
    "# print(f\"Test samples: {len(test_data_short)}\")\n",
    "\n",
    "# datasets and dataloaders\n",
    "print(\"*\" * 80)\n",
    "print(\"Creating datasets and dataloaders\")\n",
    "\n",
    "# train_dataset = TrainValCellDataset(\n",
    "#     config[\"data_path\"], \n",
    "#     train_data_short, \n",
    "#     code_tokenizer, \n",
    "#     text_tokenizer, \n",
    "#     config[\"max_length\"]\n",
    "# )\n",
    "train_sampler = CellSampler(train_data)\n",
    "# train_dataloader = DataLoader(\n",
    "#     train_dataset, \n",
    "#     config[\"batch_size\"], \n",
    "#     drop_last=True, \n",
    "#     sampler=train_sampler\n",
    "# )\n",
    "\n",
    "# valid_dataset = TrainValCellDataset(\n",
    "#     config[\"data_path\"], \n",
    "#     valid_data_short, \n",
    "#     code_tokenizer, \n",
    "#     text_tokenizer, \n",
    "#     config[\"max_length\"]\n",
    "# )\n",
    "valid_sampler = CellSampler(valid_data, config[\"random_seed\"])\n",
    "# valid_dataloader = DataLoader(\n",
    "#     valid_dataset, \n",
    "#     config[\"batch_size\"], \n",
    "#     drop_last=True, \n",
    "#     sampler=valid_sampler\n",
    "# )\n",
    "\n",
    "# test_dataset = TestCellDataset(\n",
    "#     config[\"data_path\"], \n",
    "#     test_data_short, \n",
    "#     code_tokenizer, \n",
    "#     text_tokenizer, \n",
    "#     config[\"max_length\"]\n",
    "# )\n",
    "# test_dataloader = DataLoader(test_dataset, 1, shuffle=False)\n",
    "\n",
    "# print(f\"Train dataloader length: {len(train_dataloader)}\")\n",
    "# print(f\"Validation dataloader length: {len(valid_dataloader)}\")\n",
    "# print(f\"Test dataloader length: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eccb3c913849d5</th>\n",
       "      <td>[dc781527, 1be9f69a, a5f76331, d8de70d4, 2f71f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba9116401f5b62</th>\n",
       "      <td>[f8ac744f, f1e64559, 614bde07, 34556e71, 89a51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68a12b911bf2fd</th>\n",
       "      <td>[9bb70352, e7e1d649, 47e000b6, df8ab119, b5cdd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e9a0ef816c30c</th>\n",
       "      <td>[6e68cf66, 725ec65b, 48d92830, c4866a63, 5c0e3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877bc7fb7b7b9</th>\n",
       "      <td>[28d3f8ba, c168f697, c280b26b, 837446d3, 29033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b259ea4ff078e</th>\n",
       "      <td>[c0c67aec, f11cd39a, 8410787c, 62bb4b25, d1ef9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8dc9018332a3b</th>\n",
       "      <td>[48df94f3, cd79d2c8, ea2b411d, 48901dd8, b5373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b53f841786b127</th>\n",
       "      <td>[e1196ebf, 755a0043, ae7c8d56, 23708f29, 6f2ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d1c11d28bb481</th>\n",
       "      <td>[19e02c12, 522a5a29, eabb774c, 2e7e609a, 2c615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11ff5eb3b3fa40</th>\n",
       "      <td>[43165b0d, f8ccf124, 562797f0, 3cb6b58a, c00d3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27851 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       cell_order\n",
       "id                                                               \n",
       "eccb3c913849d5  [dc781527, 1be9f69a, a5f76331, d8de70d4, 2f71f...\n",
       "ba9116401f5b62  [f8ac744f, f1e64559, 614bde07, 34556e71, 89a51...\n",
       "68a12b911bf2fd  [9bb70352, e7e1d649, 47e000b6, df8ab119, b5cdd...\n",
       "8e9a0ef816c30c  [6e68cf66, 725ec65b, 48d92830, c4866a63, 5c0e3...\n",
       "8877bc7fb7b7b9  [28d3f8ba, c168f697, c280b26b, 837446d3, 29033...\n",
       "...                                                           ...\n",
       "9b259ea4ff078e  [c0c67aec, f11cd39a, 8410787c, 62bb4b25, d1ef9...\n",
       "d8dc9018332a3b  [48df94f3, cd79d2c8, ea2b411d, 48901dd8, b5373...\n",
       "b53f841786b127  [e1196ebf, 755a0043, ae7c8d56, 23708f29, 6f2ef...\n",
       "6d1c11d28bb481  [19e02c12, 522a5a29, eabb774c, 2e7e609a, 2c615...\n",
       "11ff5eb3b3fa40  [43165b0d, f8ccf124, 562797f0, 3cb6b58a, c00d3...\n",
       "\n",
       "[27851 rows x 1 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eccb3c913849d5</th>\n",
       "      <td>[dc781527, 1be9f69a, a5f76331, d8de70d4, 2f71f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ba9116401f5b62</th>\n",
       "      <td>[f8ac744f, f1e64559, 614bde07, 34556e71, 89a51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68a12b911bf2fd</th>\n",
       "      <td>[9bb70352, e7e1d649, 47e000b6, df8ab119, b5cdd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e9a0ef816c30c</th>\n",
       "      <td>[6e68cf66, 725ec65b, 48d92830, c4866a63, 5c0e3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8877bc7fb7b7b9</th>\n",
       "      <td>[28d3f8ba, c168f697, c280b26b, 837446d3, 29033...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9b259ea4ff078e</th>\n",
       "      <td>[c0c67aec, f11cd39a, 8410787c, 62bb4b25, d1ef9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d8dc9018332a3b</th>\n",
       "      <td>[48df94f3, cd79d2c8, ea2b411d, 48901dd8, b5373...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b53f841786b127</th>\n",
       "      <td>[e1196ebf, 755a0043, ae7c8d56, 23708f29, 6f2ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6d1c11d28bb481</th>\n",
       "      <td>[19e02c12, 522a5a29, eabb774c, 2e7e609a, 2c615...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11ff5eb3b3fa40</th>\n",
       "      <td>[43165b0d, f8ccf124, 562797f0, 3cb6b58a, c00d3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27851 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       cell_order\n",
       "id                                                               \n",
       "eccb3c913849d5  [dc781527, 1be9f69a, a5f76331, d8de70d4, 2f71f...\n",
       "ba9116401f5b62  [f8ac744f, f1e64559, 614bde07, 34556e71, 89a51...\n",
       "68a12b911bf2fd  [9bb70352, e7e1d649, 47e000b6, df8ab119, b5cdd...\n",
       "8e9a0ef816c30c  [6e68cf66, 725ec65b, 48d92830, c4866a63, 5c0e3...\n",
       "8877bc7fb7b7b9  [28d3f8ba, c168f697, c280b26b, 837446d3, 29033...\n",
       "...                                                           ...\n",
       "9b259ea4ff078e  [c0c67aec, f11cd39a, 8410787c, 62bb4b25, d1ef9...\n",
       "d8dc9018332a3b  [48df94f3, cd79d2c8, ea2b411d, 48901dd8, b5373...\n",
       "b53f841786b127  [e1196ebf, 755a0043, ae7c8d56, 23708f29, 6f2ef...\n",
       "6d1c11d28bb481  [19e02c12, 522a5a29, eabb774c, 2e7e609a, 2c615...\n",
       "11ff5eb3b3fa40  [43165b0d, f8ccf124, 562797f0, 3cb6b58a, c00d3...\n",
       "\n",
       "[27851 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset_.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset_, 512, drop_last=True, sampler=train_sampler,pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset_, 512, drop_last=True, sampler=valid_sampler,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset_, 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = OrderPredictionModel(config[\"hidden_dim\"], config[\"dropout_prob\"])\n",
    "savedir = prepare_folders()\n",
    "device = get_device()\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.TrainValCellDataset at 0x2ad2183562d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется 4 GPU!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): OrderPredictionModel(\n",
       "    (bert_text): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (codebert): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSdpaSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (type_embedding): Embedding(2, 8)\n",
       "    (fc1): Linear(in_features=1552, out_features=128, bias=True)\n",
       "    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import DataParallel\n",
    "\n",
    "# Перемещение модели на несколько GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Используется {torch.cuda.device_count()} GPU!\")\n",
    "    model = DataParallel(model)\n",
    "\n",
    "# Перемещение модели на устройство (GPU)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Train model\n",
      "********************************************************************************\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8521/8521 [4:21:02<00:00,  1.84s/it]   \n",
      "Validating: 100%|██████████| 2436/2436 [27:38<00:00,  1.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5882, Valid accuracy: 0.4782\n",
      "Epoch execution time: 17321.11 seconds\n",
      "New best model saved with valid accuracy: 0.4782\n",
      "********************************************************************************\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 142/8521 [04:17<4:08:14,  1.78s/it]"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    savedir=savedir,\n",
    "    device=device,\n",
    "    epochs= 4,#config[\"epochs\"],\n",
    "    early_stopping=5,#config[\"early_stopping\"],\n",
    "    saving_freq=2,#config[\"saving_freq\"],\n",
    "    lr=config[\"learning_rate\"],\n",
    ")\n",
    "\n",
    "train_losses, valid_kendalls = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5882460865255617, 0.6910785114159398, 0.690288502927146, 0.6900499939442856]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all\n",
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.4782), tensor(0.4759), tensor(0.4759), tensor(0.4898)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_kendalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valid_kendalls)\n",
    "plt.title('Validation Kendall Tau')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Kendall Tau')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(savedir, 'training_curves.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5947136866461864]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# losses = []\n",
    "losses.append(train_losses[0])\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.6770)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kendals = []\n",
    "kendals.append(valid_kendalls[0])\n",
    "kendals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.5215), tensor(0.4915)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_kendalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_dataloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'DataLoader' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# test_dataloader.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 5/13926 [00:42<33:07:01,  8.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m model.load_state_dict(best_model_weights)\n\u001b[32m      9\u001b[39m tester = Tester(model, device)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m result = \u001b[43mtester\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mKendall Tau local score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 144\u001b[39m, in \u001b[36mTester.test\u001b[39m\u001b[34m(self, test_dataloader)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m cells, correct_order \u001b[38;5;129;01min\u001b[39;00m tqdm(test_dataloader, desc=\u001b[33m\"\u001b[39m\u001b[33mTesting\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         sorted_cells = \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcells\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcmp_to_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_custom_compare\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         sorted_order = [cell[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m sorted_cells]\n\u001b[32m    146\u001b[39m         true_order.append(correct_order)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 152\u001b[39m, in \u001b[36mTester._custom_compare\u001b[39m\u001b[34m(self, cell1, cell2)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_custom_compare\u001b[39m(\u001b[38;5;28mself\u001b[39m, cell1, cell2):\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcell1\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcell1\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcell1\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcell2\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcell2\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcell2\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.item() <= \u001b[32m0.5\u001b[39m:\n\u001b[32m    162\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[39m, in \u001b[36mDataParallel.forward\u001b[39m\u001b[34m(self, *inputs, **kwargs)\u001b[39m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.module(*inputs[\u001b[32m0\u001b[39m], **module_kwargs[\u001b[32m0\u001b[39m])\n\u001b[32m    192\u001b[39m replicas = \u001b[38;5;28mself\u001b[39m.replicate(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.device_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gather(outputs, \u001b[38;5;28mself\u001b[39m.output_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:212\u001b[39m, in \u001b[36mDataParallel.parallel_apply\u001b[39m\u001b[34m(self, replicas, inputs, kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparallel_apply\u001b[39m(\n\u001b[32m    210\u001b[39m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[32m    211\u001b[39m ) -> List[Any]:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:120\u001b[39m, in \u001b[36mparallel_apply\u001b[39m\u001b[34m(modules, inputs, kwargs_tup, devices)\u001b[39m\n\u001b[32m    118\u001b[39m         thread.join()\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     \u001b[43m_worker\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_tup\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreams\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m outputs = []\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:96\u001b[39m, in \u001b[36mparallel_apply.<locals>._worker\u001b[39m\u001b[34m(i, module, input, kwargs, device, stream)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m     95\u001b[39m         \u001b[38;5;28minput\u001b[39m = (\u001b[38;5;28minput\u001b[39m,)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m     98\u001b[39m     results[i] = output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mOrderPredictionModel.forward\u001b[39m\u001b[34m(self, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2):\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     embedding1 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_batch_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matt_mask1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell_type1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m                                            \u001b[49m\u001b[43mcode_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodebert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_model\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     embedding2 = \u001b[38;5;28mself\u001b[39m._get_batch_embeddings(input_ids2, att_mask2, cell_type2, \n\u001b[32m     46\u001b[39m                                            code_model=\u001b[38;5;28mself\u001b[39m.codebert, text_model=\u001b[38;5;28mself\u001b[39m.bert_text)\n\u001b[32m     48\u001b[39m     type_emb1 = \u001b[38;5;28mself\u001b[39m.type_embedding(cell_type1)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mOrderPredictionModel._get_batch_embeddings\u001b[39m\u001b[34m(input_ids, attention_mask, cell_type, code_model, text_model)\u001b[39m\n\u001b[32m     27\u001b[39m     code_input_ids = input_ids[code_indices]\n\u001b[32m     28\u001b[39m     code_attention_mask = attention_mask[code_indices]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     out_code = \u001b[43mcode_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_attention_mask\u001b[49m\u001b[43m)\u001b[49m.pooler_output\n\u001b[32m     30\u001b[39m     embeddings[code_indices] = out_code\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m text_mask.any():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:976\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    969\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    972\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    973\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    974\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m976\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    989\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:631\u001b[39m, in \u001b[36mRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    620\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    621\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    622\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         output_attentions,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m631\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    633\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    641\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:520\u001b[39m, in \u001b[36mRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    509\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    510\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    517\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m    518\u001b[39m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[32m    519\u001b[39m     self_attn_past_key_value = past_key_value[:\u001b[32m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m     self_attention_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m     attention_output = self_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    529\u001b[39m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:447\u001b[39m, in \u001b[36mRobertaAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    438\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    439\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    446\u001b[39m ) -> Tuple[torch.Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     self_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    449\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    456\u001b[39m     attention_output = \u001b[38;5;28mself\u001b[39m.output(self_outputs[\u001b[32m0\u001b[39m], hidden_states)\n\u001b[32m    457\u001b[39m     outputs = (attention_output,) + self_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:338\u001b[39m, in \u001b[36mRobertaSdpaSelfAttention.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    336\u001b[39m     key_layer, value_layer = past_key_value\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     key_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    339\u001b[39m     value_layer = \u001b[38;5;28mself\u001b[39m.transpose_for_scores(\u001b[38;5;28mself\u001b[39m.value(current_states))\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/a4code/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# NB! нужно тестировать на очень небольшом семпле, остальное кидать в сабмишн\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Testing model\")\n",
    "\n",
    "best_model_weights = torch.load(f\"{savedir}best_model.pt\")\n",
    "model.load_state_dict(best_model_weights)\n",
    "\n",
    "tester = Tester(model, device)\n",
    "result = tester.test(test_dataloader)\n",
    "print(f\"Kendall Tau local score: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Creating submission file\n",
      "Generating predictions for 4 test notebooks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating submission: 100%|██████████| 4/4 [01:42<00:00, 25.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to ./checkpoints/25.03.2025-01.10/submission_pair_wise_all.csv\n",
      "\n",
      "Sample of submission file:\n",
      "               id                                         cell_order\n",
      "0  0028856e09c5b7                eb293dfc 012c9d02 d22526d1 3ae7ece3\n",
      "1  0010483c12ba9b  7f270e34 54c7cab3 fe66203e 7844d5f8 5ce8863c 4...\n",
      "2  0010a919d60e4f  584f6568 aafc3d23 80e077ec b190ebb4 322850af e...\n",
      "3  0009d135ece78d  f9893819 ddfd239c c6cd22db 1372ae9b 90ed07ab 7...\n"
     ]
    }
   ],
   "source": [
    "print(\"*\" * 80)\n",
    "print(\"Creating submission file\")\n",
    "\n",
    "best_model_weights = torch.load(f\"{savedir}best_model.pt\")\n",
    "model.load_state_dict(best_model_weights)\n",
    "model.to(device)\n",
    "\n",
    "def generate_submission(model, device, test_path, submission_path):\n",
    "    test_files = os.listdir(test_path)\n",
    "    test_files = [f for f in test_files if f.endswith('.json')]\n",
    "    \n",
    "    submission_data = {'id': [], 'cell_order': []}\n",
    "    \n",
    "    print(f\"Generating predictions for {len(test_files)} test notebooks...\")\n",
    "    \n",
    "    for test_file in tqdm(test_files, desc=\"Creating submission\"):\n",
    "        notebook_id = test_file.split('.')[0]\n",
    "        \n",
    "        with open(os.path.join(test_path, test_file), 'r') as f:\n",
    "            notebook = json.load(f)\n",
    "        \n",
    "        cell_inputs = []\n",
    "        cell_ids = []\n",
    "        \n",
    "        for cell_id in notebook['source']:\n",
    "            cell_type = notebook['cell_type'][cell_id]\n",
    "            source = notebook['source'][cell_id]\n",
    "            \n",
    "            if cell_type == 'code':\n",
    "                tokenizer = code_tokenizer\n",
    "                cell_type_id = 1\n",
    "            else:\n",
    "                tokenizer = text_tokenizer\n",
    "                cell_type_id = 0\n",
    "                \n",
    "            tokens = tokenizer(\n",
    "                source,\n",
    "                padding=\"max_length\",\n",
    "                max_length=config[\"max_length\"],\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            cell_inputs.append({\n",
    "                'input_ids': tokens['input_ids'],\n",
    "                'attention_mask': tokens['attention_mask'],\n",
    "                'cell_type': torch.tensor([cell_type_id], dtype=torch.long)\n",
    "            })\n",
    "            cell_ids.append(cell_id)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sorted_ids = []\n",
    "            for i in range(len(cell_ids) - 1):\n",
    "                remaining_indices = [j for j in range(len(cell_ids)) if cell_ids[j] not in sorted_ids]\n",
    "                \n",
    "                best_score = -float('inf')\n",
    "                best_index = -1\n",
    "                \n",
    "                if i == 0:\n",
    "                    for idx in remaining_indices:\n",
    "                        cell_i = cell_inputs[idx]\n",
    "                        cell_type = cell_i['cell_type'].item()\n",
    "                        \n",
    "                        score = -1 if cell_type == 1 else 0\n",
    "                        \n",
    "                        if cell_type == 0:\n",
    "                            source = notebook['source'][cell_ids[idx]]\n",
    "                            if source.startswith('#') or 'introduction' in source.lower():\n",
    "                                score += 2\n",
    "                            \n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_index = idx\n",
    "                \n",
    "                else:\n",
    "                    prev_cell_idx = cell_ids.index(sorted_ids[-1])\n",
    "                    prev_cell = cell_inputs[prev_cell_idx]\n",
    "                    \n",
    "                    for idx in remaining_indices:\n",
    "                        curr_cell = cell_inputs[idx]\n",
    "                        \n",
    "                        output = model(\n",
    "                            prev_cell['input_ids'].to(device),\n",
    "                            prev_cell['attention_mask'].to(device),\n",
    "                            prev_cell['cell_type'].to(device),\n",
    "                            curr_cell['input_ids'].to(device),\n",
    "                            curr_cell['attention_mask'].to(device),\n",
    "                            curr_cell['cell_type'].to(device)\n",
    "                        )\n",
    "                        \n",
    "                        score = output.item()\n",
    "                        \n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_index = idx\n",
    "                \n",
    "                sorted_ids.append(cell_ids[best_index])\n",
    "            \n",
    "            for remaining_id in cell_ids:\n",
    "                if remaining_id not in sorted_ids:\n",
    "                    sorted_ids.append(remaining_id)\n",
    "\n",
    "        submission_data['id'].append(notebook_id)\n",
    "        submission_data['cell_order'].append(' '.join(sorted_ids))\n",
    "    \n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Submission file saved to {submission_path}\")\n",
    "    return submission_df\n",
    "\n",
    "test_path = \"/home/drkocharyan/ai4code/AI4Code/test/\"\n",
    "submission_path = f\"{savedir}submission_pair_wise_all.csv\"\n",
    "submission = generate_submission(model, device, test_path, submission_path)\n",
    "\n",
    "print(\"\\nSample of submission file:\")\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_path\": \"/home/drkocharyan/ai4code/AI4Code/train/\",\n",
    "    \"train_orders_path\": \"/home/drkocharyan/ai4code/AI4Code/train_orders.csv\",\n",
    "    \n",
    "    \"code_model_name\": \"microsoft/codebert-base\",\n",
    "    \"text_model_name\": \"bert-base-multilingual-uncased\",\n",
    "    \n",
    "    \"train_size\": 0.7,\n",
    "    \"valid_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \n",
    "    \"train_samples\": 25000,\n",
    "    \"valid_samples\": 5000,\n",
    "    \"test_samples\": 2000,\n",
    "    \n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout_prob\": 0.1,\n",
    "    \"max_length\": 128,\n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"early_stopping\": 5,\n",
    "    \"saving_freq\": 5,\n",
    "    \"learning_rate\": 1e-4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "     \"data_path\": \"/home/drkocharyan/ai4code/AI4Code/train/\",\n",
    "    \"train_orders_path\": \"/home/drkocharyan/ai4code/AI4Code/train_orders.csv\",\n",
    "    \"train_notebooks_path\": \"/home/drkocharyan/ai4code/AI4Code/train/\",\n",
    "    \n",
    "    \"random_seed\": 42,\n",
    "    \"train_size\": 0.7,\n",
    "    \"valid_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \n",
    "    \"debug_mode\": True,\n",
    "    \"train_sample_size\": 50000,\n",
    "    \"valid_sample_size\": 5000,\n",
    "    \"test_sample_size\": 2000,\n",
    "    \n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout_prob\": 0.1,\n",
    "    \"max_length\": 128,\n",
    "    \n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 1,\n",
    "    \n",
    "    \"savedir_name\": \"checkpoints_listwise\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, BertTokenizer, AutoModel, BertModel\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from bisect import bisect\n",
    "from time import localtime, strftime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_folders(savedir_name=\"checkpoints_listwise\"):\n",
    "    \"\"\"Prepare folders for saving model checkpoints.\"\"\"\n",
    "    current_time = strftime(\"%d.%m.%Y-%H.%M\", localtime())\n",
    "    savedir = f\"./{savedir_name}/{current_time}/\"\n",
    "\n",
    "    if not os.path.exists(f\"./{savedir_name}\"):\n",
    "        os.mkdir(f\"./{savedir_name}/\")\n",
    "    if not os.path.exists(savedir):\n",
    "        os.mkdir(savedir)\n",
    "    else:\n",
    "        for root, dirs, files in os.walk(savedir, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "\n",
    "    return savedir\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get appropriate device for training.\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    return device\n",
    "\n",
    "def count_inversions(a):\n",
    "    \"\"\"Count the number of inversions in array a.\"\"\"\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    \"\"\"Calculate the Kendall Tau correlation metric.\"\"\"\n",
    "    total_inversions = 0\n",
    "    total_2max = 0\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    ids_notebook = [item[\"id_notebook\"] for item in batch]\n",
    "    \n",
    "    cell_ids_lists = [item[\"cell_ids\"] for item in batch]\n",
    "    \n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    attention_masks = [item[\"attention_mask\"] for item in batch]\n",
    "    cell_types = [item[\"cell_types\"] for item in batch]\n",
    "    \n",
    "    return {\n",
    "        \"id_notebook\": ids_notebook,\n",
    "        \"cell_ids\": cell_ids_lists,\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_masks,\n",
    "        \"cell_types\": cell_types\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_submission(model, test_dataset, device, output_path='submission.csv'):\n",
    "\n",
    "    model.eval()\n",
    "    loader = DataLoader(test_dataset, batch_size=256, shuffle=False, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    submission_dict = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Generating predictions\"):\n",
    "            notebook_id = batch[\"id_notebook\"][0]\n",
    "            \n",
    "            if isinstance(batch[\"cell_ids\"], list):\n",
    "                cell_ids = batch[\"cell_ids\"][0]\n",
    "            else:\n",
    "                cell_ids = list(batch[\"cell_ids\"][0])\n",
    "                \n",
    "            input_ids = batch[\"input_ids\"][0].to(device)\n",
    "            att_mask = batch[\"attention_mask\"][0].to(device)\n",
    "            cell_types = batch[\"cell_types\"][0].to(device)\n",
    "\n",
    "            scores = model(input_ids, att_mask, cell_types)\n",
    "            scores_cpu = scores.cpu().numpy()\n",
    "            \n",
    "            idx_sorted = np.argsort(-scores_cpu)\n",
    "            idx_sorted = idx_sorted[:len(cell_ids)]\n",
    "            \n",
    "            predicted_ids = [cell_ids[i] for i in idx_sorted]\n",
    "            submission_dict[notebook_id] = ' '.join(predicted_ids)\n",
    "    \n",
    "    submission_df = pd.DataFrame({\"id\": list(submission_dict.keys()), \n",
    "                                 \"cell_order\": list(submission_dict.values())})\n",
    "    \n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    print(f\"Submission saved to {output_path}\")\n",
    "    \n",
    "    print(\"\\nSample of submission file:\")\n",
    "    print(submission_df.head())\n",
    "    \n",
    "    return submission_df\n",
    "\n",
    "class ListWiseCellDataset(Dataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length=128):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.data = data\n",
    "        self.notebook_ids = list(data.index)\n",
    "        self.code_tokenizer = code_tokenizer\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.notebook_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        notebook_id = self.notebook_ids[idx]\n",
    "        cell_order = self.data.loc[notebook_id, \"cell_order\"]\n",
    "        \n",
    "        if isinstance(cell_order, str):\n",
    "            cell_order = cell_order.split()\n",
    "            \n",
    "        with open(f\"{self.path}{notebook_id}.json\", \"r\") as f:\n",
    "            nb_json = json.load(f)\n",
    "\n",
    "        input_ids_list = []\n",
    "        attn_mask_list = []\n",
    "        cell_type_list = []\n",
    "\n",
    "        for cell_id in cell_order:\n",
    "            ctype = nb_json[\"cell_type\"][cell_id]\n",
    "            csource = nb_json[\"source\"][cell_id]\n",
    "\n",
    "            if ctype == \"code\":\n",
    "                tok = self.code_tokenizer(\n",
    "                    csource,\n",
    "                    max_length=self.max_length,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                cell_type_list.append(1)\n",
    "            else:  # markdown\n",
    "                tok = self.text_tokenizer(\n",
    "                    csource,\n",
    "                    max_length=self.max_length,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "                cell_type_list.append(0)\n",
    "\n",
    "            input_ids_list.append(tok[\"input_ids\"].squeeze(0))\n",
    "            attn_mask_list.append(tok[\"attention_mask\"].squeeze(0))\n",
    "\n",
    "        input_ids_tensor = torch.stack(input_ids_list, dim=0)\n",
    "        attn_mask_tensor = torch.stack(attn_mask_list, dim=0)\n",
    "        cell_type_tensor = torch.tensor(cell_type_list, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"id_notebook\": notebook_id,\n",
    "            \"cell_ids\": cell_order,\n",
    "            \"input_ids\": input_ids_tensor,\n",
    "            \"attention_mask\": attn_mask_tensor,\n",
    "            \"cell_types\": cell_type_tensor\n",
    "        }\n",
    "class ListWiseOrderPredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim=768, dropout_prob=0.1):\n",
    "        super().__init__()\n",
    "        self.codebert = AutoModel.from_pretrained(\"microsoft/codebert-base\")\n",
    "        self.bert_text = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "        self.type_embedding = nn.Embedding(2, 8)\n",
    "\n",
    "        self.proj = nn.Linear(768 + 8, hidden_dim)\n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, cell_types):\n",
    "        device = input_ids.device\n",
    "        N = input_ids.size(0)\n",
    "\n",
    "        code_mask = (cell_types == 1)\n",
    "        text_mask = (cell_types == 0)\n",
    "\n",
    "        embeddings = torch.zeros(N, 768, device=device, dtype=torch.float32)\n",
    "\n",
    "        if code_mask.any():\n",
    "            code_idx = code_mask.nonzero(as_tuple=True)[0]\n",
    "            out_code = self.codebert(\n",
    "                input_ids[code_idx],\n",
    "                attention_mask=attention_mask[code_idx]\n",
    "            ).pooler_output\n",
    "            embeddings[code_idx] = out_code\n",
    "\n",
    "        if text_mask.any():\n",
    "            text_idx = text_mask.nonzero(as_tuple=True)[0]\n",
    "            out_text = self.bert_text(\n",
    "                input_ids[text_idx],\n",
    "                attention_mask=attention_mask[text_idx]\n",
    "            ).pooler_output\n",
    "            embeddings[text_idx] = out_text\n",
    "\n",
    "        type_emb = self.type_embedding(cell_types)\n",
    "\n",
    "        x = torch.cat([embeddings, type_emb], dim=1)\n",
    "        x = self.dropout(self.act(self.proj(x)))\n",
    "        scores = self.classifier(x)\n",
    "        return scores.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listnet_loss(scores, n_items):\n",
    "    rank_tensor = torch.arange(n_items, device=scores.device, dtype=torch.float32)\n",
    "    q_unnorm = torch.exp(-rank_tensor)\n",
    "    q = q_unnorm / q_unnorm.sum()\n",
    "\n",
    "    p = F.softmax(scores, dim=0)\n",
    "    eps = 1e-10\n",
    "    loss = - (q * torch.log(p + eps)).sum()\n",
    "    return loss\n",
    "\n",
    "class ListWiseTrainer:\n",
    "    def __init__(self, model, train_dataset, valid_dataset, device, save_dir, lr=1e-4, epochs=5):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.epochs = epochs\n",
    "        self.save_dir = save_dir\n",
    "\n",
    "        self.train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True,pin_memory=True, collate_fn=custom_collate_fn)\n",
    "        self.valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=lr)\n",
    "        self.best_kendall = -999.0\n",
    "        self.best_model_state = None\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_kendalls = []\n",
    "\n",
    "    def train(self):\n",
    "        self.model.to(self.device)\n",
    "        for epoch in range(1, self.epochs+1):\n",
    "            print(f\"\\nEpoch [{epoch}/{self.epochs}]\")\n",
    "            train_loss = self._train_one_epoch()\n",
    "            val_kendall = self._validate()\n",
    "            \n",
    "            self.train_losses.append(train_loss)\n",
    "            self.valid_kendalls.append(val_kendall)\n",
    "            \n",
    "            print(f\"Train loss: {train_loss:.4f}, Valid Kendall Tau: {val_kendall:.4f}\")\n",
    "\n",
    "            if val_kendall > self.best_kendall:\n",
    "                self.best_kendall = val_kendall\n",
    "\n",
    "                self.best_model_state = {\n",
    "                    k: v.cpu() for k, v in self.model.state_dict().items()\n",
    "                }\n",
    "                print(\"New best model saved.\")\n",
    "\n",
    "        if self.best_model_state is not None:\n",
    "            torch.save(self.best_model_state, os.path.join(self.save_dir, \"best_model.pt\"))\n",
    "            print(f\"Best model with Kendall Tau={self.best_kendall:.4f} saved.\")\n",
    "            \n",
    "        return self.train_losses, self.valid_kendalls\n",
    "\n",
    "    def _train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for batch in tqdm(self.train_loader, desc=\"Training\"):\n",
    "            self.optimizer.zero_grad()\n",
    "            input_ids = batch[\"input_ids\"][0].to(self.device)\n",
    "            att_mask  = batch[\"attention_mask\"][0].to(self.device)\n",
    "            cell_types= batch[\"cell_types\"][0].to(self.device)\n",
    "            N = input_ids.size(0)\n",
    "\n",
    "            scores = self.model(input_ids, att_mask, cell_types)\n",
    "            loss = listnet_loss(scores, N)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        return total_loss / max(1, n_batches)\n",
    "\n",
    "    def _validate(self):\n",
    "        self.model.eval()\n",
    "        all_gt_orders = []\n",
    "        all_pred_orders = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in self.valid_loader:\n",
    "                notebook_id = batch[\"id_notebook\"][0]\n",
    "                \n",
    "                if isinstance(batch[\"cell_ids\"], list):\n",
    "                    cell_ids = batch[\"cell_ids\"][0]\n",
    "                else:\n",
    "                    cell_ids = list(batch[\"cell_ids\"][0])\n",
    "                \n",
    "                input_ids = batch[\"input_ids\"][0].to(self.device)\n",
    "                att_mask = batch[\"attention_mask\"][0].to(self.device)\n",
    "                cell_types = batch[\"cell_types\"][0].to(self.device)\n",
    "\n",
    "                scores = self.model(input_ids, att_mask, cell_types)\n",
    "                scores_cpu = scores.cpu().numpy()\n",
    "\n",
    "                idx_sorted = np.argsort(-scores_cpu)\n",
    "                idx_sorted = idx_sorted[:len(cell_ids)]\n",
    "                \n",
    "                predicted_ids = [cell_ids[i] for i in idx_sorted]\n",
    "\n",
    "                all_gt_orders.append(list(cell_ids))\n",
    "                all_pred_orders.append(predicted_ids)\n",
    "\n",
    "        ktau = kendall_tau(all_gt_orders, all_pred_orders)\n",
    "        return ktau\n",
    "\n",
    "class ListWiseTester:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "    \n",
    "    def test(self, test_dataset):\n",
    "        loader = DataLoader(test_dataset, batch_size=256, shuffle=False, collate_fn=custom_collate_fn)\n",
    "        all_gt_orders = []\n",
    "        all_pred_orders = []\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                if isinstance(batch[\"cell_ids\"], list):\n",
    "                    cell_ids = batch[\"cell_ids\"][0]\n",
    "                else:\n",
    "                    cell_ids = list(batch[\"cell_ids\"][0])\n",
    "                    \n",
    "                input_ids = batch[\"input_ids\"][0].to(self.device)\n",
    "                att_mask = batch[\"attention_mask\"][0].to(self.device)\n",
    "                cell_types = batch[\"cell_types\"][0].to(self.device)\n",
    "\n",
    "                scores = self.model(input_ids, att_mask, cell_types)\n",
    "                scores_cpu = scores.cpu().numpy()\n",
    "                \n",
    "                idx_sorted = np.argsort(-scores_cpu)\n",
    "                idx_sorted = idx_sorted[:len(cell_ids)]\n",
    "                \n",
    "                predicted_ids = [cell_ids[i] for i in idx_sorted]\n",
    "\n",
    "                all_gt_orders.append(list(cell_ids))\n",
    "                all_pred_orders.append(predicted_ids)\n",
    "\n",
    "        ktau = kendall_tau(all_gt_orders, all_pred_orders)\n",
    "        return ktau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Load and split data\n",
    "info = pd.read_csv(CONFIG[\"train_orders_path\"], index_col=\"id\")\n",
    "info[\"cell_order\"] = info[\"cell_order\"].apply(lambda x: x.split())\n",
    "indeces = list(info.index)\n",
    "\n",
    "rng = np.random.default_rng(CONFIG[\"random_seed\"])\n",
    "rng.shuffle(indeces)\n",
    "\n",
    "train_border = int(CONFIG[\"train_size\"] * len(indeces))\n",
    "valid_border = int((CONFIG[\"train_size\"] + CONFIG[\"valid_size\"]) * len(indeces))\n",
    "\n",
    "train_data = info.loc[indeces[:train_border]]\n",
    "valid_data = info.loc[indeces[train_border:valid_border]]\n",
    "test_data  = info.loc[indeces[valid_border:]]\n",
    "\n",
    "if CONFIG[\"debug_mode\"]:\n",
    "    train_data = train_data.iloc[:CONFIG[\"train_sample_size\"]]\n",
    "    valid_data = valid_data.iloc[:CONFIG[\"valid_sample_size\"]]\n",
    "    test_data  = test_data.iloc[:CONFIG[\"test_sample_size\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a80c1fed7cf1b7</th>\n",
       "      <td>[efd93fd9, 8b5f324d, 44f08ea5, 8a28a172, 4257e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140ec0d92d8e67</th>\n",
       "      <td>[e1df203d, 1471043e, 59056883, 8e8b37a5, ae7f9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bdefc690c0fb8f</th>\n",
       "      <td>[deee4a89, f83238cc, 432ca17b, 16636875, c33d3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e27d3ad8c97864</th>\n",
       "      <td>[05b42c18, b356682f, 343077ac, b38bd196, f9737...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70ffc5d9108413</th>\n",
       "      <td>[364c7354, ffbf800f, 60f5134b, 8e4d61aa, 40136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6e7ae6fc2a04a0</th>\n",
       "      <td>[315db33b, be37e434, 79e6e87e, a8a0328e, 29c49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f5f3b825bd5303</th>\n",
       "      <td>[212694c3, 1b687f61, f51dc9c3, 818affe1, 7d502...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07ef1fbaa82bda</th>\n",
       "      <td>[4e3d8d9d, 35a3d91e, d7378950, c5640526, 99c64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1ed45812c1d4e8</th>\n",
       "      <td>[b64cacc1, b7c14e22, 5c4752e1, 0eed0eec, 34668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d03c77f24c862d</th>\n",
       "      <td>[c5abc441, 6199316c, a30adb28, eb31759a, 5c353...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       cell_order\n",
       "id                                                               \n",
       "a80c1fed7cf1b7  [efd93fd9, 8b5f324d, 44f08ea5, 8a28a172, 4257e...\n",
       "140ec0d92d8e67  [e1df203d, 1471043e, 59056883, 8e8b37a5, ae7f9...\n",
       "bdefc690c0fb8f  [deee4a89, f83238cc, 432ca17b, 16636875, c33d3...\n",
       "e27d3ad8c97864  [05b42c18, b356682f, 343077ac, b38bd196, f9737...\n",
       "70ffc5d9108413  [364c7354, ffbf800f, 60f5134b, 8e4d61aa, 40136...\n",
       "...                                                           ...\n",
       "6e7ae6fc2a04a0  [315db33b, be37e434, 79e6e87e, a8a0328e, 29c49...\n",
       "f5f3b825bd5303  [212694c3, 1b687f61, f51dc9c3, 818affe1, 7d502...\n",
       "07ef1fbaa82bda  [4e3d8d9d, 35a3d91e, d7378950, c5640526, 99c64...\n",
       "1ed45812c1d4e8  [b64cacc1, b7c14e22, 5c4752e1, 0eed0eec, 34668...\n",
       "d03c77f24c862d  [c5abc441, 6199316c, a30adb28, eb31759a, 5c353...\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50000\n",
      "Valid size: 5000\n",
      "Test size: 2000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# Load and split data\n",
    "\n",
    "code_tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "text_tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "info = pd.read_csv(CONFIG[\"train_orders_path\"], index_col=\"id\")\n",
    "info[\"cell_order\"] = info[\"cell_order\"].apply(lambda x: x.split())\n",
    "indeces = list(info.index)\n",
    "\n",
    "rng = np.random.default_rng(CONFIG[\"random_seed\"])\n",
    "rng.shuffle(indeces)\n",
    "\n",
    "train_border = int(CONFIG[\"train_size\"] * len(indeces))\n",
    "valid_border = int((CONFIG[\"train_size\"] + CONFIG[\"valid_size\"]) * len(indeces))\n",
    "\n",
    "train_data = info.loc[indeces[:train_border]]\n",
    "valid_data = info.loc[indeces[train_border:valid_border]]\n",
    "test_data  = info.loc[indeces[valid_border:]]\n",
    "\n",
    "if CONFIG[\"debug_mode\"]:\n",
    "    train_data = train_data.iloc[:CONFIG[\"train_sample_size\"]]\n",
    "    valid_data = valid_data.iloc[:CONFIG[\"valid_sample_size\"]]\n",
    "    test_data  = test_data.iloc[:CONFIG[\"test_sample_size\"]]\n",
    "\n",
    "print(f\"Train size: {len(train_data)}\")\n",
    "print(f\"Valid size: {len(valid_data)}\")\n",
    "print(f\"Test size: {len(test_data)}\")\n",
    "\n",
    "train_dataset = ListWiseCellDataset(\n",
    "    path=CONFIG[\"train_notebooks_path\"],\n",
    "    data=train_data,\n",
    "    code_tokenizer=code_tokenizer,\n",
    "    text_tokenizer=text_tokenizer,\n",
    "    max_length=CONFIG[\"max_length\"]\n",
    ")\n",
    "\n",
    "valid_dataset = ListWiseCellDataset(\n",
    "    path=CONFIG[\"train_notebooks_path\"],\n",
    "    data=valid_data,\n",
    "    code_tokenizer=code_tokenizer,\n",
    "    text_tokenizer=text_tokenizer,\n",
    "    max_length=CONFIG[\"max_length\"]\n",
    ")\n",
    "\n",
    "test_dataset = ListWiseCellDataset(\n",
    "    path=CONFIG[\"train_notebooks_path\"],\n",
    "    data=test_data,\n",
    "    code_tokenizer=code_tokenizer,\n",
    "    text_tokenizer=text_tokenizer,\n",
    "    max_length=CONFIG[\"max_length\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ListWiseOrderPredictionModel(\n",
    "    hidden_dim=CONFIG[\"hidden_dim\"], \n",
    "    dropout_prob=CONFIG[\"dropout_prob\"]\n",
    ")\n",
    "savedir = prepare_folders(savedir_name=CONFIG[\"savedir_name\"])\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Используется 4 GPU!\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import DataParallel\n",
    "\n",
    "# Перемещение модели на несколько GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Используется {torch.cuda.device_count()} GPU!\")\n",
    "    model = DataParallel(model)\n",
    "\n",
    "# Перемещение модели на устройство (GPU)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  69%|██████▉   | 34/49 [37:41<18:34, 74.31s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = ListWiseTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=valid_dataset,\n",
    "    device=device,\n",
    "    save_dir=savedir,\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    epochs=2\n",
    ")\n",
    "train_losses, valid_kendalls = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15651656417377502]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_kendalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = ListWiseTester(model, device)\n",
    "result = tester.test(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.9877079944221343]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15651656417377502]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_kendalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = ListWiseTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=valid_dataset,\n",
    "    device=device,\n",
    "    save_dir=savedir,\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    epochs=1\n",
    ")\n",
    "train_losses, valid_kendalls = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  89%|████████▉ | 174/196 [21:56<02:48,  7.64s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = ListWiseTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    valid_dataset=valid_dataset,\n",
    "    device=device,\n",
    "    save_dir=savedir,\n",
    "    lr=CONFIG[\"learning_rate\"],\n",
    "    epochs=7\n",
    ")\n",
    "train_losses, valid_kendalls = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = ListWiseTester(model, device)\n",
    "result = tester.test(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50k 5k 2k 8 epochs\n",
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_kendalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valid_kendalls)\n",
    "plt.title('Validation Kendall Tau')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Kendall Tau')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(savedir, 'training_curves.png'))\n",
    "plt.show()\n",
    "\n",
    "best_model_path = os.path.join(savedir, \"best_model.pt\")\n",
    "best_weights = torch.load(best_model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(best_weights)\n",
    "model.to(device)\n",
    "\n",
    "tester = ListWiseTester(model, device)\n",
    "result = tester.test(test_dataset)\n",
    "print(\"*\"*80)\n",
    "print(f\"Test Kendall Tau score: {result:.4f}\")\n",
    "\n",
    "\n",
    "submission_output_path = os.path.join(savedir, \"submission.csv\")\n",
    "submission_df = generate_submission(model, test_dataset, device, output_path=submission_output_path)\n",
    "\n",
    "if CONFIG[\"debug_mode\"]:\n",
    "    print(\"\\nNote: This submission was generated in debug mode with a small test sample.\")\n",
    "    print(\"To create a full submission, set 'debug_mode': False in the configuration.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [.conda-a4code]",
   "language": "python",
   "name": "conda-env-.conda-a4code-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
