{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "from transformers import BertModel, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from time import time, localtime, strftime\n",
    "from bisect import bisect\n",
    "from functools import cmp_to_key\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config = {\n",
    "    \"data_path\": \"../AI4Code_data/train/\",\n",
    "    \"train_orders_path\": \"../AI4Code_data/train_orders.csv\",\n",
    "    \n",
    "    \"code_model_name\": \"microsoft/codebert-base\",\n",
    "    \"text_model_name\": \"bert-base-multilingual-uncased\",\n",
    "    \n",
    "    \"train_size\": 0.7,\n",
    "    \"valid_size\": 0.2,\n",
    "    \"test_size\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \n",
    "    \"train_samples\": 100,\n",
    "    \"valid_samples\": 10,\n",
    "    \"test_samples\": 10,\n",
    "    \n",
    "    \"hidden_dim\": 128,\n",
    "    \"dropout_prob\": 0.1,\n",
    "    \"max_length\": 128,\n",
    "    \n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 5,\n",
    "    \"early_stopping\": 5,\n",
    "    \"saving_freq\": 5,\n",
    "    \"learning_rate\": 1e-4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def prepare_folders():\n",
    "    current_time = strftime(\"%d.%m.%Y-%H.%M\", localtime())\n",
    "    savedir = f\"./checkpoints/{current_time}/\"\n",
    "\n",
    "    if not os.path.exists(\"./checkpoints\"):\n",
    "        os.mkdir(\"./checkpoints/\")\n",
    "    if not os.path.exists(savedir):\n",
    "        os.mkdir(savedir)\n",
    "    else:\n",
    "        for root, dirs, files in os.walk(savedir, topdown=False):\n",
    "            for name in files:\n",
    "                os.remove(os.path.join(root, name))\n",
    "            for name in dirs:\n",
    "                os.rmdir(os.path.join(root, name))\n",
    "\n",
    "    return savedir\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "    return device\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "\n",
    "class Cell:\n",
    "    def __init__(self, input_ids, att_mask, cell_type):\n",
    "        self.input_ids = input_ids\n",
    "        self.att_mask = att_mask\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "    def get(self):\n",
    "        return (self.input_ids, self.att_mask, self.cell_type)\n",
    "\n",
    "\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.code_tokenizer = code_tokenizer\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.files = {}\n",
    "\n",
    "        for filename in tqdm(self.data.index, desc=\"Processing dataset\"):\n",
    "            cells_dict = {}\n",
    "            cells = self.data.loc[filename, \"cell_order\"]\n",
    "            with open(f\"{path}{filename}.json\") as file:\n",
    "                json_code = json.load(file)\n",
    "            for cell in cells:\n",
    "                input_ids, att_mask, cell_type = self.prepare_data(\n",
    "                    json_code[\"cell_type\"][cell], json_code[\"source\"][cell]\n",
    "                )\n",
    "                cells_dict[cell] = Cell(input_ids, att_mask, cell_type)\n",
    "            self.files[filename] = cells_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self, cell_type, cell_content):\n",
    "        if cell_type == \"code\":\n",
    "            tokenizer = self.code_tokenizer\n",
    "            type_label = 1\n",
    "        else:\n",
    "            tokenizer = self.text_tokenizer\n",
    "            type_label = 0\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            cell_content,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "    \n",
    "        type_tensor = torch.tensor([type_label], dtype=torch.long)\n",
    "\n",
    "        return (tokens[\"input_ids\"], tokens[\"attention_mask\"], type_tensor)\n",
    "\n",
    "\n",
    "class TrainValCellDataset(CellDataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length):\n",
    "        super().__init__(path, data, code_tokenizer, text_tokenizer, max_length)\n",
    "\n",
    "        n_pair = 0\n",
    "        for row_index in self.data.index:\n",
    "            n_pair += len(self.data.loc[row_index, \"cell_order\"]) - 1\n",
    "        self.n_pair = n_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_pair\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = idx[0]\n",
    "        first_cell_id = idx[1]\n",
    "        second_cell_id = idx[2]\n",
    "\n",
    "        first_position = self.data.loc[filename, \"cell_order\"].index(first_cell_id)\n",
    "        second_position = self.data.loc[filename, \"cell_order\"].index(second_cell_id)\n",
    "        order = 0 if first_position < second_position else 1\n",
    "\n",
    "        return ((self.files[filename][first_cell_id].get(), self.files[filename][second_cell_id].get()), order)\n",
    "\n",
    "\n",
    "class TestCellDataset(CellDataset):\n",
    "    def __init__(self, path, data, code_tokenizer, text_tokenizer, max_length):\n",
    "        super().__init__(path, data, code_tokenizer, text_tokenizer, max_length)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_id = self.data.iloc[idx].name\n",
    "        correct_order = self.data.iloc[idx].item()\n",
    "        random_order = correct_order.copy()\n",
    "        np.random.shuffle(random_order)\n",
    "\n",
    "        cells = []\n",
    "        for index in random_order:\n",
    "            input_ids, att_mask, cell_type = self.files[file_id][index].get()\n",
    "            cells.append([index, input_ids, att_mask, cell_type])\n",
    "\n",
    "        return cells, correct_order\n",
    "\n",
    "\n",
    "class CellSampler(Sampler):\n",
    "    def __init__(self, data, seed=None):\n",
    "        self.data = data\n",
    "        self.seed = seed\n",
    "        n_pair = 0\n",
    "        for row_index in self.data.index:\n",
    "            n_pair += len(self.data.loc[row_index, \"cell_order\"]) - 1\n",
    "        self.n_pair = n_pair\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_pair\n",
    "\n",
    "    def __iter__(self):\n",
    "        pairs = []\n",
    "        for row_index in self.data.index:\n",
    "            cells = self.data.loc[row_index, \"cell_order\"].copy()\n",
    "            if self.seed:\n",
    "                rng = np.random.default_rng(self.seed)\n",
    "                rng.shuffle(cells)\n",
    "            else:\n",
    "                np.random.shuffle(cells)\n",
    "            for cell_index in range(len(cells) - 1):\n",
    "                pairs.append([row_index, cells[cell_index], cells[cell_index + 1]])\n",
    "\n",
    "        for pair in pairs:\n",
    "            yield pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "class OrderPredictionModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, dropout_prob=0.1):\n",
    "        super(OrderPredictionModel, self).__init__()\n",
    "\n",
    "        self.bert_text = BertModel.from_pretrained(config[\"text_model_name\"])\n",
    "        self.codebert = AutoModel.from_pretrained(config[\"code_model_name\"])\n",
    "\n",
    "        self.type_embedding = nn.Embedding(2, 8)\n",
    "        self.fc1 = nn.Linear(768 * 2 + 8 * 2, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_batch_embeddings(input_ids, attention_mask, cell_type, code_model, text_model):\n",
    "        device = input_ids.device\n",
    "        batch_size = input_ids.size(0)\n",
    "        hidden_size = code_model.config.hidden_size\n",
    "        embeddings = torch.zeros(batch_size, hidden_size, device=device, dtype=torch.float32)\n",
    "\n",
    "        code_mask = (cell_type == 1)\n",
    "        text_mask = (cell_type == 0)\n",
    "\n",
    "        if code_mask.any():\n",
    "            code_indices = code_mask.nonzero(as_tuple=True)[0]\n",
    "            code_input_ids = input_ids[code_indices]\n",
    "            code_attention_mask = attention_mask[code_indices]\n",
    "            out_code = code_model(code_input_ids, attention_mask=code_attention_mask).pooler_output\n",
    "            embeddings[code_indices] = out_code\n",
    "\n",
    "        if text_mask.any():\n",
    "            text_indices = text_mask.nonzero(as_tuple=True)[0]\n",
    "            text_input_ids = input_ids[text_indices]\n",
    "            text_attention_mask = attention_mask[text_indices]\n",
    "            out_text = text_model(text_input_ids, attention_mask=text_attention_mask).pooler_output\n",
    "            embeddings[text_indices] = out_text\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def forward(self, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2):\n",
    "        embedding1 = self._get_batch_embeddings(input_ids1, att_mask1, cell_type1, \n",
    "                                                code_model=self.codebert, text_model=self.bert_text)\n",
    "\n",
    "        embedding2 = self._get_batch_embeddings(input_ids2, att_mask2, cell_type2, \n",
    "                                               code_model=self.codebert, text_model=self.bert_text)\n",
    "\n",
    "        type_emb1 = self.type_embedding(cell_type1)\n",
    "        type_emb2 = self.type_embedding(cell_type2)\n",
    "\n",
    "        combined = torch.cat([embedding1, type_emb1, embedding2, type_emb2], dim=1)\n",
    "        x = torch.relu(self.bn1(self.fc1(combined)))\n",
    "        x = self.dropout(x)\n",
    "        output = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return output.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataloader,\n",
    "        valid_dataloader,\n",
    "        savedir,\n",
    "        device,\n",
    "        epochs=10,\n",
    "        early_stopping=5,\n",
    "        saving_freq=5,\n",
    "        lr=1e-4,\n",
    "    ):\n",
    "        self.device = device\n",
    "        self.model = model.to(device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.valid_dataloader = valid_dataloader\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.optimizer = optim.NAdam(self.model.parameters(), lr=lr)\n",
    "        self.epochs = epochs\n",
    "        self.early_stopping = early_stopping\n",
    "        self.best_score = -float(\"inf\")\n",
    "        self.best_model = None\n",
    "        self.savedir = savedir\n",
    "        self.saving_freq = saving_freq\n",
    "\n",
    "        self.train_losses = []\n",
    "        self.valid_kendalls = []\n",
    "\n",
    "    def train(self):\n",
    "        early_stopping_remaining = self.early_stopping\n",
    "        print(\"*\" * 80)\n",
    "        print(f\"Train model\")\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            print(\"*\" * 80)\n",
    "            print(f\"Epoch {epoch}/{self.epochs}\")\n",
    "            start_time = time()\n",
    "            train_loss = self._train_one_epoch()\n",
    "            valid_score = self._validate()\n",
    "\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.valid_kendalls.append(valid_score)\n",
    "            \n",
    "            print(f\"Train loss: {train_loss:.4f}, Valid accuracy: {valid_score:.4f}\")\n",
    "            print(f\"Epoch execution time: {time() - start_time:.2f} seconds\")\n",
    "\n",
    "            if valid_score > self.best_score:\n",
    "                early_stopping_remaining = self.early_stopping\n",
    "                self.best_score = valid_score\n",
    "                self.best_model = {k: v.cpu() for k, v in self.model.state_dict().items()}\n",
    "                print(f\"New best model saved with valid accuracy: {valid_score:.4f}\")\n",
    "            else:\n",
    "                early_stopping_remaining -= 1\n",
    "\n",
    "            if epoch % self.saving_freq == 0:\n",
    "                self._save_checkpoint(epoch, train_loss)\n",
    "\n",
    "            if not early_stopping_remaining:\n",
    "                print(f\"Training stopped at {epoch} epoch\")\n",
    "                break\n",
    "\n",
    "        if self.best_model:\n",
    "            torch.save(self.best_model, f\"{self.savedir}best_model.pt\")\n",
    "            print(\"Best model saved as 'best_model.pt'.\")\n",
    "        \n",
    "        return self.train_losses, self.valid_kendalls\n",
    "\n",
    "    def _train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        train_loss = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        for (first_cell, second_cell), train_label in tqdm(self.train_dataloader, desc=\"Training\"):\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(\n",
    "                first_cell[0].squeeze(1).to(self.device),\n",
    "                first_cell[1].squeeze(1).to(self.device),\n",
    "                first_cell[2].squeeze(1).to(self.device),\n",
    "                second_cell[0].squeeze(1).to(self.device),\n",
    "                second_cell[1].squeeze(1).to(self.device),\n",
    "                second_cell[2].squeeze(1).to(self.device),\n",
    "            )\n",
    "            loss = self.criterion(output, train_label.float().to(self.device))\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        return train_loss / n_batches\n",
    "\n",
    "    def _validate(self):\n",
    "        self.model.eval()\n",
    "        score = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (first_cell, second_cell), correct_order in tqdm(self.valid_dataloader, desc=\"Validating\"):\n",
    "                n_batches += 1\n",
    "                output = self.model(\n",
    "                    first_cell[0].squeeze(1).to(self.device),\n",
    "                    first_cell[1].squeeze(1).to(self.device),\n",
    "                    first_cell[2].squeeze(1).to(self.device),\n",
    "                    second_cell[0].squeeze(1).to(self.device),\n",
    "                    second_cell[1].squeeze(1).to(self.device),\n",
    "                    second_cell[2].squeeze(1).to(self.device),\n",
    "                )\n",
    "\n",
    "                output += 0.5\n",
    "                order = output.to(dtype=torch.int32).cpu()\n",
    "                score += sum(order == correct_order).sum() / correct_order.shape[0]\n",
    "\n",
    "        score /= n_batches\n",
    "        return score\n",
    "\n",
    "    def _save_checkpoint(self, epoch, train_loss):\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": {k: v.cpu() for k, v in self.model.state_dict().items()},\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"train_loss\": train_loss,\n",
    "        }\n",
    "        checkpoint_path = f\"{self.savedir}checkpoint_epoch_{epoch}.pt\"\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        print(f\"Checkpoint saved at {checkpoint_path}.\")\n",
    "\n",
    "\n",
    "class Tester:\n",
    "    def __init__(self, model, device):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def test(self, test_dataloader):\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        true_order = []\n",
    "        predicted_order = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for cells, correct_order in tqdm(test_dataloader, desc=\"Testing\"):\n",
    "                sorted_cells = sorted(cells, key=cmp_to_key(self._custom_compare))\n",
    "                sorted_order = [cell[0] for cell in sorted_cells]\n",
    "                true_order.append(correct_order)\n",
    "                predicted_order.append(sorted_order)\n",
    "\n",
    "        return kendall_tau(true_order, predicted_order)\n",
    "\n",
    "    def _custom_compare(self, cell1, cell2):\n",
    "        result = self.model(\n",
    "            cell1[1].squeeze(0).to(self.device),\n",
    "            cell1[2].squeeze(0).to(self.device),\n",
    "            cell1[3].squeeze(0).to(self.device),\n",
    "            cell2[1].squeeze(0).to(self.device),\n",
    "            cell2[2].squeeze(0).to(self.device),\n",
    "            cell2[3].squeeze(0).to(self.device),\n",
    "        )\n",
    "\n",
    "        if result.item() <= 0.5:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Reading data\n",
      "Train samples: 10\n",
      "Validation samples: 10\n",
      "Test samples: 10\n",
      "********************************************************************************\n",
      "Creating datasets and dataloaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dataset: 100%|██████████| 10/10 [00:00<00:00, 71.69it/s]\n",
      "Processing dataset: 100%|██████████| 10/10 [00:00<00:00, 63.54it/s]\n",
      "Processing dataset: 100%|██████████| 10/10 [00:00<00:00, 126.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader length: 7\n",
      "Validation dataloader length: 6\n",
      "Test dataloader length: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# загрузка данных\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Reading data\")\n",
    "\n",
    "code_tokenizer = AutoTokenizer.from_pretrained(config[\"code_model_name\"])\n",
    "text_tokenizer = BertTokenizer.from_pretrained(config[\"text_model_name\"])\n",
    "\n",
    "info = pd.read_csv(config[\"train_orders_path\"], index_col=\"id\")\n",
    "info[\"cell_order\"] = info[\"cell_order\"].apply(lambda x: x.split())\n",
    "indeces = list(info.index)\n",
    "\n",
    "rng = np.random.default_rng(config[\"random_seed\"])\n",
    "rng.shuffle(indeces)\n",
    "\n",
    "train_border = int(config[\"train_size\"] * len(indeces))\n",
    "valid_border = int((config[\"train_size\"] + config[\"valid_size\"]) * len(indeces))\n",
    "\n",
    "train_data = info.loc[indeces[:train_border]]\n",
    "valid_data = info.loc[indeces[train_border:valid_border]]\n",
    "test_data = info.loc[indeces[valid_border:]]\n",
    "\n",
    "# подвыборки для теста\n",
    "train_data_short = train_data.iloc[:config[\"train_samples\"]]\n",
    "valid_data_short = valid_data.iloc[:config[\"valid_samples\"]]\n",
    "test_data_short = test_data.iloc[:config[\"test_samples\"]]\n",
    "\n",
    "print(f\"Train samples: {len(train_data_short)}\")\n",
    "print(f\"Validation samples: {len(valid_data_short)}\")\n",
    "print(f\"Test samples: {len(test_data_short)}\")\n",
    "\n",
    "# datasets and dataloaders\n",
    "print(\"*\" * 80)\n",
    "print(\"Creating datasets and dataloaders\")\n",
    "\n",
    "train_dataset = TrainValCellDataset(\n",
    "    config[\"data_path\"], \n",
    "    train_data_short, \n",
    "    code_tokenizer, \n",
    "    text_tokenizer, \n",
    "    config[\"max_length\"]\n",
    ")\n",
    "train_sampler = CellSampler(train_data_short)\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    config[\"batch_size\"], \n",
    "    drop_last=True, \n",
    "    sampler=train_sampler\n",
    ")\n",
    "\n",
    "valid_dataset = TrainValCellDataset(\n",
    "    config[\"data_path\"], \n",
    "    valid_data_short, \n",
    "    code_tokenizer, \n",
    "    text_tokenizer, \n",
    "    config[\"max_length\"]\n",
    ")\n",
    "valid_sampler = CellSampler(valid_data_short, config[\"random_seed\"])\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset, \n",
    "    config[\"batch_size\"], \n",
    "    drop_last=True, \n",
    "    sampler=valid_sampler\n",
    ")\n",
    "\n",
    "test_dataset = TestCellDataset(\n",
    "    config[\"data_path\"], \n",
    "    test_data_short, \n",
    "    code_tokenizer, \n",
    "    text_tokenizer, \n",
    "    config[\"max_length\"]\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, 1, shuffle=False)\n",
    "\n",
    "print(f\"Train dataloader length: {len(train_dataloader)}\")\n",
    "print(f\"Validation dataloader length: {len(valid_dataloader)}\")\n",
    "print(f\"Test dataloader length: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: mps\n",
      "********************************************************************************\n",
      "Train model\n",
      "********************************************************************************\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [01:32<00:00, 13.26s/it]\n",
      "Validating: 100%|██████████| 6/6 [00:08<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7347, Valid accuracy: 0.5130\n",
      "Epoch execution time: 100.95 seconds\n",
      "New best model saved with valid accuracy: 0.5130\n",
      "********************************************************************************\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [01:09<00:00,  9.94s/it]\n",
      "Validating: 100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.7329, Valid accuracy: 0.5000\n",
      "Epoch execution time: 75.73 seconds\n",
      "********************************************************************************\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:23<00:00,  3.38s/it]\n",
      "Validating: 100%|██████████| 6/6 [00:06<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6591, Valid accuracy: 0.5104\n",
      "Epoch execution time: 29.83 seconds\n",
      "********************************************************************************\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:23<00:00,  3.29s/it]\n",
      "Validating: 100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5718, Valid accuracy: 0.5599\n",
      "Epoch execution time: 29.09 seconds\n",
      "New best model saved with valid accuracy: 0.5599\n",
      "********************************************************************************\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 7/7 [00:24<00:00,  3.44s/it]\n",
      "Validating: 100%|██████████| 6/6 [00:06<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5401, Valid accuracy: 0.5964\n",
      "Epoch execution time: 30.20 seconds\n",
      "New best model saved with valid accuracy: 0.5964\n",
      "Checkpoint saved at ./checkpoints/23.03.2025-11.42/checkpoint_epoch_5.pt.\n",
      "Best model saved as 'best_model.pt'.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "model = OrderPredictionModel(config[\"hidden_dim\"], config[\"dropout_prob\"])\n",
    "savedir = prepare_folders()\n",
    "device = get_device()\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    valid_dataloader=valid_dataloader,\n",
    "    savedir=savedir,\n",
    "    device=device,\n",
    "    epochs=config[\"epochs\"],\n",
    "    early_stopping=config[\"early_stopping\"],\n",
    "    saving_freq=config[\"saving_freq\"],\n",
    "    lr=config[\"learning_rate\"],\n",
    ")\n",
    "\n",
    "train_losses, valid_kendalls = trainer.train()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(valid_kendalls)\n",
    "plt.title('Validation Kendall Tau')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Kendall Tau')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(savedir, 'training_curves.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Testing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/10 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_model_weights)\n\u001b[1;32m      9\u001b[0m tester \u001b[38;5;241m=\u001b[39m Tester(model, device)\n\u001b[0;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m tester\u001b[38;5;241m.\u001b[39mtest(test_dataloader)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKendall Tau local score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 143\u001b[0m, in \u001b[0;36mTester.test\u001b[0;34m(self, test_dataloader)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cells, correct_order \u001b[38;5;129;01min\u001b[39;00m tqdm(test_dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 143\u001b[0m         sorted_cells \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(cells, key\u001b[38;5;241m=\u001b[39mcmp_to_key(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_compare))\n\u001b[1;32m    144\u001b[0m         sorted_order \u001b[38;5;241m=\u001b[39m [cell[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m sorted_cells]\n\u001b[1;32m    145\u001b[0m         true_order\u001b[38;5;241m.\u001b[39mappend(correct_order)\n",
      "Cell \u001b[0;32mIn[9], line 151\u001b[0m, in \u001b[0;36mTester._custom_compare\u001b[0;34m(self, cell1, cell2)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_custom_compare\u001b[39m(\u001b[38;5;28mself\u001b[39m, cell1, cell2):\n\u001b[0;32m--> 151\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    152\u001b[0m         cell1[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    153\u001b[0m         cell1[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    154\u001b[0m         cell1[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    155\u001b[0m         cell2[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    156\u001b[0m         cell2[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    157\u001b[0m         cell2[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    158\u001b[0m     )\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m, in \u001b[0;36mOrderPredictionModel.forward\u001b[0;34m(self, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2):\n\u001b[0;32m---> 42\u001b[0m     embedding1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batch_embeddings(input_ids1, att_mask1, cell_type1, \n\u001b[1;32m     43\u001b[0m                                             code_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebert, text_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_text)\n\u001b[1;32m     45\u001b[0m     embedding2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batch_embeddings(input_ids2, att_mask2, cell_type2, \n\u001b[1;32m     46\u001b[0m                                            code_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebert, text_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_text)\n\u001b[1;32m     48\u001b[0m     type_emb1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_embedding(cell_type1)\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mOrderPredictionModel._get_batch_embeddings\u001b[0;34m(input_ids, attention_mask, cell_type, code_model, text_model)\u001b[0m\n\u001b[1;32m     23\u001b[0m text_mask \u001b[38;5;241m=\u001b[39m (cell_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code_mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m---> 26\u001b[0m     code_indices \u001b[38;5;241m=\u001b[39m code_mask\u001b[38;5;241m.\u001b[39mnonzero(as_tuple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m     code_input_ids \u001b[38;5;241m=\u001b[39m input_ids[code_indices]\n\u001b[1;32m     28\u001b[0m     code_attention_mask \u001b[38;5;241m=\u001b[39m attention_mask[code_indices]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# NB! нужно тестировать на очень небольшом семпле, остальное кидать в сабмишн\n",
    "\n",
    "print(\"*\" * 80)\n",
    "print(\"Testing model\")\n",
    "\n",
    "best_model_weights = torch.load(f\"{savedir}best_model.pt\")\n",
    "model.load_state_dict(best_model_weights)\n",
    "\n",
    "tester = Tester(model, device)\n",
    "result = tester.test(test_dataloader)\n",
    "print(f\"Kendall Tau local score: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "Creating submission file\n",
      "Generating predictions for 4 test notebooks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating submission:   0%|          | 0/4 [00:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 114\u001b[0m\n\u001b[1;32m    112\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../AI4Code_data/test/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m submission_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msavedir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m submission \u001b[38;5;241m=\u001b[39m generate_submission(model, device, test_path, submission_path)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSample of submission file:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mprint\u001b[39m(submission\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[0;32mIn[14], line 83\u001b[0m, in \u001b[0;36mgenerate_submission\u001b[0;34m(model, device, test_path, submission_path)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m remaining_indices:\n\u001b[1;32m     81\u001b[0m     curr_cell \u001b[38;5;241m=\u001b[39m cell_inputs[idx]\n\u001b[0;32m---> 83\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(\n\u001b[1;32m     84\u001b[0m         prev_cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     85\u001b[0m         prev_cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     86\u001b[0m         prev_cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     87\u001b[0m         curr_cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     88\u001b[0m         curr_cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     89\u001b[0m         curr_cell[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     90\u001b[0m     )\n\u001b[1;32m     92\u001b[0m     score \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 45\u001b[0m, in \u001b[0;36mOrderPredictionModel.forward\u001b[0;34m(self, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids1, att_mask1, cell_type1, input_ids2, att_mask2, cell_type2):\n\u001b[1;32m     42\u001b[0m     embedding1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batch_embeddings(input_ids1, att_mask1, cell_type1, \n\u001b[1;32m     43\u001b[0m                                             code_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebert, text_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_text)\n\u001b[0;32m---> 45\u001b[0m     embedding2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_batch_embeddings(input_ids2, att_mask2, cell_type2, \n\u001b[1;32m     46\u001b[0m                                            code_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodebert, text_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_text)\n\u001b[1;32m     48\u001b[0m     type_emb1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_embedding(cell_type1)\n\u001b[1;32m     49\u001b[0m     type_emb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_embedding(cell_type2)\n",
      "Cell \u001b[0;32mIn[8], line 36\u001b[0m, in \u001b[0;36mOrderPredictionModel._get_batch_embeddings\u001b[0;34m(input_ids, attention_mask, cell_type, code_model, text_model)\u001b[0m\n\u001b[1;32m     34\u001b[0m     text_input_ids \u001b[38;5;241m=\u001b[39m input_ids[text_indices]\n\u001b[1;32m     35\u001b[0m     text_attention_mask \u001b[38;5;241m=\u001b[39m attention_mask[text_indices]\n\u001b[0;32m---> 36\u001b[0m     out_text \u001b[38;5;241m=\u001b[39m text_model(text_input_ids, attention_mask\u001b[38;5;241m=\u001b[39mtext_attention_mask)\u001b[38;5;241m.\u001b[39mpooler_output\n\u001b[1;32m     37\u001b[0m     embeddings[text_indices] \u001b[38;5;241m=\u001b[39m out_text\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m   1143\u001b[0m     embedding_output,\n\u001b[1;32m   1144\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m   1145\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1146\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m   1147\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m   1148\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1149\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1150\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1151\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1152\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1153\u001b[0m )\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    696\u001b[0m         hidden_states,\n\u001b[1;32m    697\u001b[0m         attention_mask,\n\u001b[1;32m    698\u001b[0m         layer_head_mask,\n\u001b[1;32m    699\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    700\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    701\u001b[0m         past_key_value,\n\u001b[1;32m    702\u001b[0m         output_attentions,\n\u001b[1;32m    703\u001b[0m     )\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[1;32m    586\u001b[0m         hidden_states,\n\u001b[1;32m    587\u001b[0m         attention_mask,\n\u001b[1;32m    588\u001b[0m         head_mask,\n\u001b[1;32m    589\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    590\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mself_attn_past_key_value,\n\u001b[1;32m    591\u001b[0m     )\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[1;32m    516\u001b[0m         hidden_states,\n\u001b[1;32m    517\u001b[0m         attention_mask,\n\u001b[1;32m    518\u001b[0m         head_mask,\n\u001b[1;32m    519\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    520\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    521\u001b[0m         past_key_value,\n\u001b[1;32m    522\u001b[0m         output_attentions,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:440\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    438\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mscaled_dot_product_attention(\n\u001b[1;32m    441\u001b[0m     query_layer,\n\u001b[1;32m    442\u001b[0m     key_layer,\n\u001b[1;32m    443\u001b[0m     value_layer,\n\u001b[1;32m    444\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    445\u001b[0m     dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_prob \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    446\u001b[0m     is_causal\u001b[38;5;241m=\u001b[39mis_causal,\n\u001b[1;32m    447\u001b[0m )\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    450\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"*\" * 80)\n",
    "print(\"Creating submission file\")\n",
    "\n",
    "best_model_weights = torch.load(f\"{savedir}best_model.pt\")\n",
    "model.load_state_dict(best_model_weights)\n",
    "model.to(device)\n",
    "\n",
    "def generate_submission(model, device, test_path, submission_path):\n",
    "    test_files = os.listdir(test_path)\n",
    "    test_files = [f for f in test_files if f.endswith('.json')]\n",
    "    \n",
    "    submission_data = {'id': [], 'cell_order': []}\n",
    "    \n",
    "    print(f\"Generating predictions for {len(test_files)} test notebooks...\")\n",
    "    \n",
    "    for test_file in tqdm(test_files, desc=\"Creating submission\"):\n",
    "        notebook_id = test_file.split('.')[0]\n",
    "        \n",
    "        with open(os.path.join(test_path, test_file), 'r') as f:\n",
    "            notebook = json.load(f)\n",
    "        \n",
    "        cell_inputs = []\n",
    "        cell_ids = []\n",
    "        \n",
    "        for cell_id in notebook['source']:\n",
    "            cell_type = notebook['cell_type'][cell_id]\n",
    "            source = notebook['source'][cell_id]\n",
    "            \n",
    "            if cell_type == 'code':\n",
    "                tokenizer = code_tokenizer\n",
    "                cell_type_id = 1\n",
    "            else:\n",
    "                tokenizer = text_tokenizer\n",
    "                cell_type_id = 0\n",
    "                \n",
    "            tokens = tokenizer(\n",
    "                source,\n",
    "                padding=\"max_length\",\n",
    "                max_length=config[\"max_length\"],\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            cell_inputs.append({\n",
    "                'input_ids': tokens['input_ids'],\n",
    "                'attention_mask': tokens['attention_mask'],\n",
    "                'cell_type': torch.tensor([cell_type_id], dtype=torch.long)\n",
    "            })\n",
    "            cell_ids.append(cell_id)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            sorted_ids = []\n",
    "            for i in range(len(cell_ids) - 1):\n",
    "                remaining_indices = [j for j in range(len(cell_ids)) if cell_ids[j] not in sorted_ids]\n",
    "                \n",
    "                best_score = -float('inf')\n",
    "                best_index = -1\n",
    "                \n",
    "                if i == 0:\n",
    "                    for idx in remaining_indices:\n",
    "                        cell_i = cell_inputs[idx]\n",
    "                        cell_type = cell_i['cell_type'].item()\n",
    "                        \n",
    "                        score = -1 if cell_type == 1 else 0\n",
    "                        \n",
    "                        if cell_type == 0:\n",
    "                            source = notebook['source'][cell_ids[idx]]\n",
    "                            if source.startswith('#') or 'introduction' in source.lower():\n",
    "                                score += 2\n",
    "                            \n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_index = idx\n",
    "                \n",
    "                else:\n",
    "                    prev_cell_idx = cell_ids.index(sorted_ids[-1])\n",
    "                    prev_cell = cell_inputs[prev_cell_idx]\n",
    "                    \n",
    "                    for idx in remaining_indices:\n",
    "                        curr_cell = cell_inputs[idx]\n",
    "                        \n",
    "                        output = model(\n",
    "                            prev_cell['input_ids'].to(device),\n",
    "                            prev_cell['attention_mask'].to(device),\n",
    "                            prev_cell['cell_type'].to(device),\n",
    "                            curr_cell['input_ids'].to(device),\n",
    "                            curr_cell['attention_mask'].to(device),\n",
    "                            curr_cell['cell_type'].to(device)\n",
    "                        )\n",
    "                        \n",
    "                        score = output.item()\n",
    "                        \n",
    "                        if score > best_score:\n",
    "                            best_score = score\n",
    "                            best_index = idx\n",
    "                \n",
    "                sorted_ids.append(cell_ids[best_index])\n",
    "            \n",
    "            for remaining_id in cell_ids:\n",
    "                if remaining_id not in sorted_ids:\n",
    "                    sorted_ids.append(remaining_id)\n",
    "\n",
    "        submission_data['id'].append(notebook_id)\n",
    "        submission_data['cell_order'].append(' '.join(sorted_ids))\n",
    "    \n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Submission file saved to {submission_path}\")\n",
    "    return submission_df\n",
    "\n",
    "test_path = \"../AI4Code_data/test/\"\n",
    "submission_path = f\"{savedir}submission.csv\"\n",
    "submission = generate_submission(model, device, test_path, submission_path)\n",
    "\n",
    "print(\"\\nSample of submission file:\")\n",
    "print(submission.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
